<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="MLDM Koblenz: ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Machine Learning and Data Mining course (Uni-Koblenz)</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/gesiscss/mlkoblenz">View on GitHub</a>

          <h1 id="project_title">MLDM Koblenz</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/gesiscss/mlkoblenz/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/gesiscss/mlkoblenz/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a id="welcome-to-ml" class="anchor" href="#welcome-to-css" aria-hidden="true"><span class="octicon octicon-link"></span></a>Welcome to the website of Machine Learning and Data Mining course.</h3>
<p>On this page, we want to provide you with the most important information and course material for the course. Here, we publish slides for lectures and tutorials, exercises and home assignments. You can simply sync this Github repository for always being up-to-date and having access to all course materials!</p>

<!--p>The ipython notebooks for the assignments and tutorials can also be viewed rendered on  <a href="http://nbviewer.ipython.org/github/gesiscss/csskoblenz/tree/gh-pages/materials/">nbviewer</a>.<p-->

<h3>
<a id="lectures" class="anchor" href="#lectures" aria-hidden="true"><span class="octicon octicon-link"></span></a>Lectures</h3>
<p> Lectures take place every week on Wednesdays, 10 a.m. in room H 010. The following agenda is a first layout and may change during the course.</p>

<ul>
  <li>28.10. Introduction & data mining process</li>
  <li>04.11. Clustering I: task & evaluation, k-means, m-medoids</li>
  <li>11.11. Clustering II: EM-Algorithm, density-based clustering</li>
  <li>18.11. Clustering III: hierarchical Clustering, Subspace Clustering, further methods</li>
  <li>25.11. Classification I: task & evaluation, Naive Bayes</li>
  <li>02.12. <b>NO COURSE</b></li>
  <li>09.12. Classification II: nearest neighbor, decision trees</li>
  <li>09.12. Classification III: Ensemble learning, random forests (time slot of tutorial)</li>
  <li>16.12. Classification IV: Support vector machines</li>
  <li>13.01. Association rule mining</li>
  <li>20.01. Subgroup discovery and exceptional model mining</li>
  <li>27.01. Pre-processing; matrix factorization</li>
  <li>03.02. Sequential data</li>
  <li>10.02. Bayesian learning</li>
  <li>24.02. <b>Final exam</b> (most likely)</li>
</ul>

<h3>
<a id="tutorials" class="anchor" href="#tutorials" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tutorials</h3>
<p> Tutorials take place about every two week on Wednesdays, 2 p.m. in room E 427. The exact dates are:</p>

<ul>
  <li>28.10. Basic statistics and data preparation: <a href="materials/tutorials/mldm2015-exercise1-task.zip" aria-hidden="true">Exercise task</a>  - <a href="materials/tutorials/mldm2015-exercise1-solution.zip" aria-hidden="true">Exercise solution</a></li>
  <li>11.11. </li>
  <li>25.11. </li>
  <li>16.12. </li>
  <li>13.01. </li>
  <li>27.01. </li>
</ul>

<h3>
<a id="assignments" class="anchor" href="#assignments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Assignments</h3>
<p> Home assignments are mandatory and to be solved in groups of 2-3 participants. You must complete at least 5 of the 6 home assignments to be admitted to the final exam.</p>

<ul>
  <li>1. Home Assignment: <a href="materials/tutorials/mldm2015-exercise1-task.zip" aria-hidden="true">Task </a><br />
  Submit at latest by 10th of November</li>
</ul>

<h3>
<a id="literature" class="anchor" href="#literature" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recommended Literature</h3>
<ul>
  <li>T. Mitchell: "Machine Learning", 1997</li>
  <li>J. Han, M. Kamber, J. Pei: "Data Mining: Concepts and Techniques", 2011</li>
  <li>I. Witten, E. Frank, M. Hall: "Data Mining: Practical Machine Learning Tools and Techniques", 2011</li>
  <li>C. Bishop: "Pattern Recognition and Machine Learning", 2008 </li>
  <li>M. Ester, J. Sander: "Knowledge Discovery in Databases: Techniken und Anwendungen", 2013 (german language)</li>
</ul>
<p>More literature can be found in the lecture slides</p>

<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span class="octicon octicon-link"></span></a>Team</h3>

<p>The course will be coached by the following persons:</p>

<ul>
  <li>Markus Strohmaier <a href="mailto:markus.strohmaier@gesis.org">markus.strohmaier@gesis.org</a></li>
  <li>Florian Lemmerich <a href="mailto:florian.lemmerich@gesis.org">florian.lemmerich@gesis.org</a></li>
  <li>Philipp Singer <a href="mailto:philipp.singer@gesis.org">philipp.singer@gesis.org</a></li>
  <li>Christoph Kling <a href="mailto:christoph.kling@gesis.org">christoph.kling@gesis.org</a></li>
</ul>

<p>For inquiries please consult the newsgroup! (.infko.mldm)</p>
  </body>
</html>